# Import necessary packages

%matplotlib inline
%config InlineBackend.figure_format = 'retina'

import numpy as np
import torch

import helper

import matplotlib.pyplot as plt

# The MNIST datasets are hosted on yann.lecun.com that has moved under CloudFlare protection
# Run this script to enable the datasets download
# Reference: https://github.com/pytorch/vision/issues/1938

from six.moves import urllib
opener = urllib.request.build_opener()
opener.addheaders = [('User-agent', 'Mozilla/5.0')]
urllib.request.install_opener(opener)
### Run this cell

from torchvision import datasets, transforms

# Define a transform to normalize the data
transform = transforms.Compose([transforms.ToTensor(),
                              transforms.Normalize((0.5,), (0.5,)),
                              ])

# Download and load the training data
trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

dataiter = iter(trainloader)
images, labels = dataiter.next()
print(type(images))
print(images.shape)
print(labels.shape)

plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');

#Flatten images
images.shape

inputs = images.view(images.shape[0],-1)
inputs.shape

#Building multiclass neural net for digit classification
def sigmoid(x):
  return 1/(1+torch.exp(-x))
w1=torch.randn((784,256))
b1 = torch.randn((256))
w2 = torch.randn((256,10))
b2 = torch.randn((10))

h = sigmoid(torch.mm(inputs,w1)+b1)
out = sigmoid(torch.mm(h,w2)+b2)

# Get probability of belonging to each class=> softmax
def softmaxFunc(x):
  return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)


probabilities = softmaxFunc(out)
sum(probabilities)

probabilities
# Does it have the right shape? Should be (64, 10)
print(probabilities.shape)
# Does it sum to 1?
print(probabilities.sum(dim=1))

def relu(x):
  return max(x,0)
